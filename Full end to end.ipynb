{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full end-to-end integration of our solution.  Each test image is first put through the trained CNN model to determine what the machine type is.  The image is then put through the OpenCV EAST model to find the potential location of all text in the image.  We then use the pixel data to create a new dataset using the relartive pixel locations to each other.  This data is then combined with the predicted machine type put put through the trained MLP.  Each and every identified text location is predcited as either PII or nonPII.  If predicted as PII, the program then blacks out that data prior to saving the edited photo.  nothing is done if the data is predicted to be nonPII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Import required modules\n",
    "import cv2 as cv\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "\n",
    "confThreshold = 0.00000001\n",
    "nmsThreshold = 0.5\n",
    "inpWidth = 320\n",
    "inpHeight = 320\n",
    "model = 'frozen_east_text_detection.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "df = pickle.load( open( \"/home/ubuntu/efs/acrin_by_machine/machine_photos/df_save_full.pkl\", \"rb\" ) )\n",
    "#df['machine']=0\n",
    "for index,row in df.iterrows():\n",
    "    df.loc[index,'machine'] = row.fileName.split('/')[-2][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1203 16:51:18.064619 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1203 16:51:18.093061 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1203 16:51:18.099294 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1203 16:51:18.123700 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1203 16:51:18.124501 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1203 16:51:21.591031 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1203 16:51:21.834687 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1203 16:51:22.618530 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W1203 16:51:44.532723 140394239682368 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import tensorflow as tf\n",
    "\n",
    "CLASSES = 6\n",
    "    \n",
    "# setup model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "#base_model = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add more layers\n",
    "machine_model = Sequential()\n",
    "machine_model.add(base_model)\n",
    "machine_model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "\n",
    "machine_model.add(Dense(CLASSES, activation='softmax'))\n",
    "#model = Model(inputs=base_model.input, outputs=predictions)\n",
    "   \n",
    "# transfer learning - set all layers of the base model to frozen\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze the last x layers from bottom\n",
    "x = 11\n",
    "for layer in base_model.layers[-x:]:\n",
    "     layer.trainable = True\n",
    "    \n",
    "machine_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "machine_model.load_weights('/home/ubuntu/efs/acrin_by_machine/machine_photos/saved_weights_0_hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(num):\n",
    "    WIDTH = 299\n",
    "    HEIGHT = 299\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    import os\n",
    "    from PIL import Image\n",
    "    from keras.preprocessing import image\n",
    "    from keras.models import load_model\n",
    "    from tqdm import tqdm\n",
    "    import cv2\n",
    "\n",
    "    X = []\n",
    "    X_p = []\n",
    "    Y = []\n",
    "    files = []\n",
    "    image_name = []\n",
    "\n",
    "    img = image.load_img(df.iloc[num].fileName, target_size=(HEIGHT, WIDTH))\n",
    "    x = image.img_to_array(img)\n",
    "    x = cv2.flip(x, 1 )\n",
    "    x = cv2.flip(x, 0 )\n",
    "    x = preprocess_input(x)\n",
    "    X.append(np.array(x))\n",
    "    X=np.array(X)\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = df.index[(df['use'] == 'test') & (df['good'] == 1)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_train_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-97f68d0fe4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_train_array' is not defined"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for i in test_list:\n",
    "    temp = create_train_array(i)\n",
    "    temp = temp.reshape((299,299,3))\n",
    "    X.append(temp)\n",
    "    print(int(df.iloc[i].machine)-1,end=' ')\n",
    "X=np.array(X)\n",
    "machine_pred = machine_model.predict(X)\n",
    "machine_pred = np.argmax(machine_pred, axis=1)\n",
    "machine_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fileName    /home/ubuntu/efs/acrin_by_machine/machine_phot...\n",
       "good                                                        1\n",
       "machc                                                       0\n",
       "use                                                     valid\n",
       "path        /home/ubuntu/efs/acrin_by_machine/machine_phot...\n",
       "machine                                                     1\n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a7e9f5ac9ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "temp = temp.reshape((299,299,3))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_rect_mach1(bc,ec,br,er,centr,centc,old_size,ratio,sc,sr,new_im):\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "\n",
    "    box1_ulc = left+int(650*ratio)+sc\n",
    "    box1_ulr = top+int(550*ratio)+sr\n",
    "\n",
    "    box1_lrc = right + int(1450*ratio)+sc\n",
    "    box1_lrr = bottom + int(650*ratio)+sr\n",
    "    \n",
    "    \n",
    "    box2_ulc = left+int(650*ratio)+sc\n",
    "    box2_ulr = top+int(650*ratio)+sr\n",
    "\n",
    "    box2_lrc = right + int(1450*ratio)+sc\n",
    "    box2_lrr = bottom + int(750*ratio)+sr\n",
    "\n",
    "\n",
    "    box3_ulc = left+int(2750*ratio)+sc\n",
    "    box3_ulr = top+int(620*ratio)+sr\n",
    "\n",
    "    box3_lrc = right + int(3400*ratio)+sc\n",
    "    box3_lrr = bottom + int(705*ratio)+sr\n",
    "\n",
    "    #print(ratio,sc,sr)\n",
    "    \n",
    "    if (box1_ulc < centc < box1_lrc) & (box1_ulr < centr < box1_lrr):\n",
    "        return(True)\n",
    "    if (box2_ulc < centc < box2_lrc) & (box2_ulr < centr < box2_lrr):\n",
    "        return(True)\n",
    "    if (box3_ulc < centc < box3_lrc) & (box3_ulr < centr < box3_lrr):\n",
    "        return(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_rect_mach2(bc,ec,br,er,centr,centc,old_size,ratio,sc,sr,new_im):\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "\n",
    "\n",
    "    box1_ulc = left+int(530*ratio)+sc\n",
    "    box1_ulr = top+int(550*ratio)+sr\n",
    "\n",
    "    box1_lrc = right + int(1485*ratio)+sc\n",
    "    box1_lrr = bottom + int(655*ratio)+sr\n",
    "    \n",
    "    \n",
    "    box2_ulc = left+int(530*ratio)+sc\n",
    "    box2_ulr = top+int(650*ratio)+sr\n",
    "\n",
    "    box2_lrc = right + int(1485*ratio)+sc\n",
    "    box2_lrr = bottom + int(730*ratio)+sr\n",
    "\n",
    "\n",
    "    box3_ulc = left+int(1495*ratio)+sc\n",
    "    box3_ulr = top+int(550*ratio)+sr\n",
    "\n",
    "    box3_lrc = right + int(2620*ratio)+sc\n",
    "    box3_lrr = bottom + int(655*ratio)+sr\n",
    "\n",
    "    \n",
    "    box4_ulc = left+int(1495*ratio)+sc\n",
    "    box4_ulr = top+int(650*ratio)+sr\n",
    "\n",
    "\n",
    "    box4_lrc = right + int(2620*ratio)+sc\n",
    "    box4_lrr = bottom + int(730*ratio)+sr\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if (box1_ulc < centc < box1_lrc) & (box1_ulr < centr < box1_lrr):\n",
    "        return(True)\n",
    "    if (box2_ulc < centc < box2_lrc) & (box2_ulr < centr < box2_lrr):\n",
    "        return(True)\n",
    "    if (box3_ulc < centc < box3_lrc) & (box3_ulr < centr < box3_lrr):\n",
    "        return(True)\n",
    "    if (box4_ulc < centc < box4_lrc) & (box4_ulr < centr < box4_lrr):\n",
    "        return(True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_rect_mach3(bc,ec,br,er,centr,centc,old_size,ratio,sc,sr,new_im):\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "\n",
    "    box1_ulc = left+int(351*ratio)+sc\n",
    "    box1_ulr = top+int(470*ratio)+sr\n",
    "\n",
    "    box1_lrc = right + int(1450*ratio)+sc\n",
    "    box1_lrr = bottom + int(549*ratio)+sr\n",
    "    \n",
    "    \n",
    "    box2_ulc = left+int(1455*ratio)+sc\n",
    "    box2_ulr = top+int(465*ratio)+sr\n",
    "\n",
    "    box2_lrc = right + int(2440*ratio)+sc\n",
    "    box2_lrr = bottom + int(544*ratio)+sr\n",
    "\n",
    "\n",
    "    box3_ulc = left+int(351*ratio)+sc\n",
    "    box3_ulr = top+int(560*ratio)+sr\n",
    "\n",
    "    box3_lrc = right + int(1450*ratio)+sc\n",
    "    box3_lrr = bottom + int(638*ratio)+sr\n",
    "\n",
    "    \n",
    "    box4_ulc = left+int(2445*ratio)+sc\n",
    "    box4_ulr = top+int(460*ratio)+sr\n",
    "\n",
    "\n",
    "    box4_lrc = right + int(2900*ratio)+sc\n",
    "    box4_lrr = bottom + int(539*ratio)+sr\n",
    "\n",
    "\n",
    "    box5_ulc = left+int(2445*ratio)+sc\n",
    "    box5_ulr = top+int(550*ratio)+sr\n",
    "\n",
    "    box5_lrc = right + int(2900*ratio)+sc\n",
    "    box5_lrr = bottom + int(628*ratio)+sr\n",
    "\n",
    "\n",
    "    \n",
    "    if (box1_ulc < centc < box1_lrc) & (box1_ulr < centr < box1_lrr):\n",
    "        return(True)\n",
    "    if (box2_ulc < centc < box2_lrc) & (box2_ulr < centr < box2_lrr):\n",
    "        return(True)\n",
    "    if (box3_ulc < centc < box3_lrc) & (box3_ulr < centr < box3_lrr):\n",
    "        return(True)\n",
    "    if (box4_ulc < centc < box4_lrc) & (box4_ulr < centr < box4_lrr):\n",
    "        return(True)\n",
    "    if (box5_ulc < centc < box5_lrc) & (box5_ulr < centr < box5_lrr):\n",
    "        return(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_rect_mach4(bc,ec,br,er,centr,centc,old_size,ratio,sc,sr,new_im):\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "\n",
    "\n",
    "    box1_ulc = left+int(950*ratio)+sc\n",
    "    box1_ulr = top+int(450*ratio)+sr\n",
    "\n",
    "    box1_lrc = right + int(2050*ratio)+sc\n",
    "    box1_lrr = bottom + int(549*ratio)+sr\n",
    "    \n",
    "\n",
    "    box2_ulc = left+int(530*ratio)+sc\n",
    "    box2_ulr = top+int(549*ratio)+sr\n",
    "\n",
    "    box2_lrc = right + int(1550*ratio)+sc\n",
    "    box2_lrr = bottom + int(648*ratio)+sr\n",
    "\n",
    "\n",
    "    box3_ulc = left+int(2050*ratio)+sc\n",
    "    box3_ulr = top+int(450*ratio)+sr\n",
    "\n",
    "    box3_lrc = right + int(2890*ratio)+sc\n",
    "    box3_lrr = bottom + int(544*ratio)+sr\n",
    "\n",
    "    \n",
    "    box4_ulc = left+int(1550*ratio)+sc\n",
    "    box4_ulr = top+int(550*ratio)+sr\n",
    "\n",
    "\n",
    "    box4_lrc = right + int(2480*ratio)+sc\n",
    "    box4_lrr = bottom + int(648*ratio)+sr\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if (box1_ulc < centc < box1_lrc) & (box1_ulr < centr < box1_lrr):\n",
    "        return(True)\n",
    "    if (box2_ulc < centc < box2_lrc) & (box2_ulr < centr < box2_lrr):\n",
    "        return(True)\n",
    "    if (box3_ulc < centc < box3_lrc) & (box3_ulr < centr < box3_lrr):\n",
    "        return(True)\n",
    "    if (box4_ulc < centc < box4_lrc) & (box4_ulr < centr < box4_lrr):\n",
    "        return(True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_rect_mach5(bc,ec,br,er,centr,centc,old_size,ratio,sc,sr,new_im):\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "    \n",
    "    \n",
    "    box1_ulc = left+int(500*ratio)+sc\n",
    "    box1_ulr = top+int(650*ratio)+sr\n",
    "\n",
    "    box1_lrc = right + int(1400*ratio)+sc\n",
    "    box1_lrr = bottom + int(750*ratio)+sr\n",
    "    \n",
    "    \n",
    "    box2_ulc = left+int(500*ratio)+sc\n",
    "    box2_ulr = top+int(750*ratio)+sr\n",
    "\n",
    "    box2_lrc = right + int(1400*ratio)+sc\n",
    "    box2_lrr = bottom + int(850*ratio)+sr\n",
    "\n",
    "\n",
    "    box3_ulc = left+int(1400*ratio)+sc\n",
    "    box3_ulr = top+int(650*ratio)+sr\n",
    "\n",
    "    box3_lrc = right + int(2300*ratio)+sc\n",
    "    box3_lrr = bottom + int(750*ratio)+sr\n",
    "\n",
    "    \n",
    "    box4_ulc = left+int(2600*ratio)+sc\n",
    "    box4_ulr = top+int(650*ratio)+sr\n",
    "\n",
    "\n",
    "    box4_lrc = right + int(3300*ratio)+sc\n",
    "    box4_lrr = bottom + int(750*ratio)+sr\n",
    "\n",
    "\n",
    "    box5_ulc = left+int(2600*ratio)+sc\n",
    "    box5_ulr = top+int(750*ratio)+sr\n",
    "\n",
    "    box5_lrc = right + int(3300*ratio)+sc\n",
    "    box5_lrr = bottom + int(850*ratio)+sr\n",
    "\n",
    "\n",
    "    \n",
    "    if (box1_ulc < centc < box1_lrc) & (box1_ulr < centr < box1_lrr):\n",
    "        return(True)\n",
    "    if (box2_ulc < centc < box2_lrc) & (box2_ulr < centr < box2_lrr):\n",
    "        return(True)\n",
    "    if (box3_ulc < centc < box3_lrc) & (box3_ulr < centr < box3_lrr):\n",
    "        return(True)\n",
    "    if (box4_ulc < centc < box4_lrc) & (box4_ulr < centr < box4_lrr):\n",
    "        return(True)\n",
    "    if (box5_ulc < centc < box5_lrc) & (box5_ulr < centr < box5_lrr):\n",
    "        return(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_rect_mach6(bc,ec,br,er,centr,centc,old_size,ratio,sc,sr,new_im):\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "    \n",
    "    box1_ulc = left+int(300*ratio)+sc\n",
    "    box1_ulr = top+int(450*ratio)+sr\n",
    "\n",
    "    box1_lrc = right + int(1100*ratio)+sc\n",
    "    box1_lrr = bottom + int(520*ratio)+sr\n",
    "    \n",
    "    \n",
    "    box2_ulc = left+int(300*ratio)+sc\n",
    "    box2_ulr = top+int(520*ratio)+sr\n",
    "\n",
    "    box2_lrc = right + int(1100*ratio)+sc\n",
    "    box2_lrr = bottom + int(590*ratio)+sr\n",
    "\n",
    "\n",
    "    box3_ulc = left+int(300*ratio)+sc\n",
    "    box3_ulr = top+int(590*ratio)+sr\n",
    "\n",
    "    box3_lrc = right + int(1100*ratio)+sc\n",
    "    box3_lrr = bottom + int(660*ratio)+sr\n",
    "\n",
    "    \n",
    "    box4_ulc = left+int(300*ratio)+sc\n",
    "    box4_ulr = top+int(660*ratio)+sr\n",
    "\n",
    "\n",
    "    box4_lrc = right + int(1100*ratio)+sc\n",
    "    box4_lrr = bottom + int(730*ratio)+sr\n",
    "\n",
    "    box5_ulc = left+int(2280*ratio)+sc\n",
    "    box5_ulr = top+int(430*ratio)+sr\n",
    "\n",
    "\n",
    "    box5_lrc = right + int(3400*ratio)+sc\n",
    "    box5_lrr = bottom + int(505*ratio)+sr\n",
    "    \n",
    "    if (box1_ulc < centc < box1_lrc) & (box1_ulr < centr < box1_lrr):\n",
    "        return(True)\n",
    "    if (box2_ulc < centc < box2_lrc) & (box2_ulr < centr < box2_lrr):\n",
    "        return(True)\n",
    "    if (box3_ulc < centc < box3_lrc) & (box3_ulr < centr < box3_lrr):\n",
    "        return(True)\n",
    "    if (box4_ulc < centc < box4_lrc) & (box4_ulr < centr < box4_lrr):\n",
    "        return(True)\n",
    "    if (box5_ulc < centc < box5_lrc) & (box5_ulr < centr < box5_lrr):\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(scores, geometry, scoreThresh,img_name):\n",
    "    detections = []\n",
    "    confidences = []\n",
    "    \n",
    "    \n",
    "    ############ CHECK DIMENSIONS AND SHAPES OF geometry AND scores ############\n",
    "    assert len(scores.shape) == 4, \"Incorrect dimensions of scores\"\n",
    "    assert len(geometry.shape) == 4, \"Incorrect dimensions of geometry\"\n",
    "    assert scores.shape[0] == 1, \"Invalid dimensions of scores\"\n",
    "    assert geometry.shape[0] == 1, \"Invalid dimensions of geometry\"\n",
    "    assert scores.shape[1] == 1, \"Invalid dimensions of scores\"\n",
    "    assert geometry.shape[1] == 5, \"Invalid dimensions of geometry\"\n",
    "    assert scores.shape[2] == geometry.shape[2], \"Invalid dimensions of scores and geometry\"\n",
    "    assert scores.shape[3] == geometry.shape[3], \"Invalid dimensions of scores and geometry\"\n",
    "    height = scores.shape[2]\n",
    "    width = scores.shape[3]\n",
    "    for y in range(0, height):\n",
    "\n",
    "        # Extract data from scores\n",
    "        scoresData = scores[0][0][y]\n",
    "        x0_data = geometry[0][0][y]\n",
    "        x1_data = geometry[0][1][y]\n",
    "        x2_data = geometry[0][2][y]\n",
    "        x3_data = geometry[0][3][y]\n",
    "        anglesData = geometry[0][4][y]\n",
    "        for x in range(0, width):\n",
    "            score = scoresData[x]\n",
    "\n",
    "            # If score is lower than threshold score, move to next x\n",
    "            if(score < scoreThresh):\n",
    "                continue\n",
    "\n",
    "            # Calculate offset\n",
    "            offsetX = x * 4.0\n",
    "            offsetY = y * 4.0\n",
    "            angle = anglesData[x]\n",
    "\n",
    "            # Calculate cos and sin of angle\n",
    "            cosA = math.cos(angle)\n",
    "            sinA = math.sin(angle)\n",
    "            h = x0_data[x] + x2_data[x]\n",
    "            w = x1_data[x] + x3_data[x]\n",
    "\n",
    "            # Calculate offset\n",
    "            offset = ([offsetX + cosA * x1_data[x] + sinA * x2_data[x], offsetY - sinA * x1_data[x] + cosA * x2_data[x]])\n",
    "\n",
    "            # Find points for rectangle\n",
    "            p1 = (-sinA * h + offset[0], -cosA * h + offset[1])\n",
    "            p3 = (-cosA * w + offset[0],  sinA * w + offset[1])\n",
    "            center = (0.5*(p1[0]+p3[0]), 0.5*(p1[1]+p3[1]))\n",
    "            #center = (0.5*(p1[0]+p3[0])+w_off, 0.5*(p1[1]+p3[1])+h_off)\n",
    "            #detections.append((center, (w,h), -1*angle * 180.0 / math.pi))\n",
    "            detections.append((center, (w,h),0.0))\n",
    "            \n",
    "            confidences.append(float(score))\n",
    "\n",
    "    # Return detections and confidences\n",
    "    return [detections, confidences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_points(this_image,test,boxx):\n",
    "    confThreshold = 0.00005\n",
    "    nmsThreshold = 0.25\n",
    "    inpWidth = 320\n",
    "    inpHeight = 320\n",
    "    import cv2\n",
    "    slices = 3\n",
    "\n",
    "    net = cv.dnn.readNet('frozen_east_text_detection.pb')\n",
    "    outputLayers = []\n",
    "    outputLayers.append(\"feature_fusion/Conv_7/Sigmoid\")\n",
    "    outputLayers.append(\"feature_fusion/concat_3\")\n",
    "\n",
    "    point_data = []\n",
    "    inpWidth = 320\n",
    "    inpHeight = 320    \n",
    "    # Open a video file or an image file or a camera stream\n",
    "    cap = cv.VideoCapture(this_image)\n",
    "    hasFrame, frame = cap.read()\n",
    "    # Get frame height and width\n",
    "    height_ = frame.shape[0]\n",
    "    width_ = frame.shape[1]\n",
    "    rW = width_ / float(inpWidth)\n",
    "    rH = height_ / float(inpHeight)\n",
    "    # Create a 4D blob from frame.\n",
    "    blob = cv.dnn.blobFromImage(frame, 1.0, (inpWidth, inpHeight), (123.68, 116.78, 103.94), True, False)\n",
    "\n",
    "    # Run the model\n",
    "    net.setInput(blob)\n",
    "    output = net.forward(outputLayers)\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
    "    # Get scores and geometry\n",
    "    scores = output[0]\n",
    "    geometry = output[1]\n",
    "    [boxes, confidences] = decode(scores, geometry, confThreshold,this_image)\n",
    "    # Apply NMS\n",
    "    indices = cv.dnn.NMSBoxesRotated(boxes, confidences, confThreshold,nmsThreshold)\n",
    "    #print(confThreshold)\n",
    "    #print(nmsThreshold)\n",
    "    row_off = (this_image.split('/')[-1].split('_')[-2])\n",
    "    col_off = (this_image.split('/')[-1].split('_')[-3])\n",
    "    #print(row_off,col_off) \n",
    "    for i in indices:\n",
    "        # get 4 corners of the rotated rect\n",
    "        vertices = cv.boxPoints(boxes[i[0]])\n",
    "        # scale the bounding box coordinates based on the respective ratios\n",
    "        c1 = 0\n",
    "        c2 = 0\n",
    "        r1 = 0\n",
    "        r2 = 0\n",
    "        for j in range(4):\n",
    "            vertices[j][0] *= rW\n",
    "            vertices[j][1] *= rH\n",
    "        for j in range(4):\n",
    "            p1 = (int(vertices[j][0]+int(row_off)), int(vertices[j][1]+int(col_off)))\n",
    "            p2 = (int(vertices[(j + 1) % 4][0]+int(row_off)), int(vertices[(j + 1) % 4][1]+int(col_off)))\n",
    "            #print(p1,p2)\n",
    "            if j == 0:\n",
    "                c1 = p1[0]\n",
    "                r1 = p1[1]\n",
    "            if  c1 != p2[0]:\n",
    "                c2 = p2[0]\n",
    "            if r1 != p2[1]:\n",
    "                r2 = p2[1]\n",
    "        if c1 < c2:\n",
    "            bc = c1\n",
    "            ec = c2\n",
    "        else:\n",
    "            bc = c2\n",
    "            ec = c1\n",
    "        if r1 < r2:\n",
    "            br = r1\n",
    "            er = r2\n",
    "        else:\n",
    "            br = r2\n",
    "            er = r1\n",
    "        #print(bc,br,ec,er)\n",
    "        centr = br + int((er-br)/2)\n",
    "        centc = bc + int((ec-bc)/2)\n",
    "        #print(centc,centr)\n",
    "        if (centr>0) & (centc>0):\n",
    "            test.append((centc,centr))\n",
    "            boxx.append([bc,br,ec,er])\n",
    "            #cv.rectangle(img, (bc,br),(ec,er), (0,255,0), 10)\n",
    "\n",
    "    return(test,boxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(num):\n",
    "    confThreshold = 0.00005\n",
    "    nmsThreshold = 0.25\n",
    "    inpWidth = 320\n",
    "    inpHeight = 320\n",
    "    import cv2\n",
    "    slices = 3\n",
    "\n",
    "    net = cv.dnn.readNet('frozen_east_text_detection.pb')\n",
    "    outputLayers = []\n",
    "    outputLayers.append(\"feature_fusion/Conv_7/Sigmoid\")\n",
    "    outputLayers.append(\"feature_fusion/concat_3\")\n",
    "\n",
    "    count = 0\n",
    "    scale_ratio=.85\n",
    "    scale_sr=.1\n",
    "    scale_sc=.1\n",
    "\n",
    "    data_df = pd.DataFrame(columns=['fileName','ratio','sr','sc','machine', 'boxx'])\n",
    "    this_mach = df.iloc[image_num].fileName\n",
    "\n",
    "    this_frame = df.iloc[image_num]\n",
    "    my_image=this_frame.fileName\n",
    "    stime=time.time()\n",
    "    img = cv.imread(my_image)\n",
    "    \n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    ratio=rand_scale = random.uniform(scale_ratio,1)\n",
    "    rand_scale = random.uniform(-scale_sr,scale_sr)\n",
    "    sr=int(img.shape[0]*rand_scale)\n",
    "    rand_scale = random.uniform(-scale_sc,scale_sc)\n",
    "    sc=int(img.shape[1]*rand_scale)\n",
    "\n",
    "    old_size = img.shape[:2] # old_size is in (height, width) format\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    # new_size should be in (width, height) format\n",
    "\n",
    "    im = cv.resize(img, (new_size[1], new_size[0]))\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "\n",
    "    if top+bottom+new_size[0] < old_size[0]:\n",
    "        top += 1\n",
    "    if left+right+new_size[1] < old_size[1]:\n",
    "        left += 1\n",
    "\n",
    "    color = [0, 0, 0]\n",
    "    img= cv.copyMakeBorder(im, top, bottom, left, right, cv.BORDER_CONSTANT,\n",
    "        value=color)\n",
    "\n",
    "\n",
    "    rows,cols,_ = img.shape\n",
    "    M = np.float32([[1,0,sc],[0,1,sr]])\n",
    "    img = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "    split_1 = int(img.shape[0]/slices)\n",
    "    split_2 = int(img.shape[1]/slices)\n",
    "    for r in range(0,img.shape[0],split_1):\n",
    "        for c in range(0,img.shape[1],split_2):\n",
    "            cv2.imwrite('/home/ubuntu/opencveast/img_'+str(r)+'_'+str(c)+'_.png',img[r:r+split_1, c:c+split_2,:])\n",
    "\n",
    "            nr = r + int((img.shape[0]/slices)/2)\n",
    "            nc = c + int((img.shape[1]/slices)/2)\n",
    "            cv2.imwrite('/home/ubuntu/opencveast/img_'+str(r)+'_'+str(nc)+'_.png',img[r:r+split_1, nc:nc+split_2,:])\n",
    "            cv2.imwrite('/home/ubuntu/opencveast/img_'+str(nr)+'_'+str(c)+'_.png',img[nr:nr+split_1, c:c+split_2,:])\n",
    "    img_list = glob.glob('/home/ubuntu/opencveast/img*')\n",
    "    cnt = 1\n",
    "    test = []\n",
    "    boxx = []\n",
    "    for this_image in img_list:\n",
    "        test,boxx = create_data_points(this_image,test,boxx)\n",
    "\n",
    "    data_df = data_df.append({'fileName': this_frame.fileName,\n",
    "                                'machine':machine_pred[0]+1, \n",
    "                                'point_data': test,\n",
    "                                'boxx' : boxx,\n",
    "                                'ratio' :ratio,\n",
    "                                'sr':sr,\n",
    "                                'sc':sc\n",
    "                               }, ignore_index=True)\n",
    "    return(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_set(test_df,mach_pred,image_num):    \n",
    "    test_data_set = pd.DataFrame(columns=['machine','ul','ll','ur','lr','ulx','llx','urx','lrx','uly','lly','ury','lry','ed_ul','ed_ll','ed_ur','ed_lr',\n",
    "                                     'vd_ul','vd_ll','vd_ur','vd_lr','hd_ul','hd_ll','hd_ur','hd_lr','class'])\n",
    "    #try:\n",
    "    img = cv.imread(test_df.loc[0].fileName)\n",
    "    this_item = test_df.loc[0].point_data\n",
    "    this_boxx = test_df.loc[0].boxx\n",
    "\n",
    "    dist_list = []\n",
    "    for item in this_item:\n",
    "        dist_list.append(distance.euclidean((0,0),item))\n",
    "    ul = np.argmin(dist_list)\n",
    "    dist_list = []\n",
    "    for item in this_item:\n",
    "        dist_list.append(distance.euclidean((0,img.shape[0]),item))\n",
    "    ll = np.argmin(dist_list)\n",
    "    dist_list = []\n",
    "    for item in this_item:\n",
    "        dist_list.append(distance.euclidean((img.shape[1],0),item))\n",
    "    ur = np.argmin(dist_list)\n",
    "    dist_list = []\n",
    "    for item in this_item:\n",
    "        dist_list.append(distance.euclidean((img.shape[1],img.shape[0]),item))\n",
    "    lr = np.argmin(dist_list)\n",
    "\n",
    "    for item in range(len(this_item)):\n",
    "        test_data_set = test_data_set.append({'machine':test_df.loc[0].machine,\n",
    "                                    'class':1,\n",
    "                                    'ul':dist_list[ul],\n",
    "                                    'll':dist_list[ll],\n",
    "                                    'ur':dist_list[ur],\n",
    "                                    'lr':dist_list[lr],\n",
    "                                    'ulx':this_item[ul][0],\n",
    "                                    'llx':this_item[ll][0],\n",
    "                                    'urx':this_item[ur][0],\n",
    "                                    'lrx':this_item[lr][0],\n",
    "                                    'uly':this_item[ul][1],\n",
    "                                    'lly':this_item[ll][1],\n",
    "                                    'ury':this_item[ur][1],\n",
    "                                    'lry':this_item[lr][1],\n",
    "                                    'boxx' : this_boxx[item],\n",
    "                                    'ed_ul':distance.euclidean(0,this_item[ul],this_item[item]),\n",
    "                                    'ed_ll':distance.euclidean(0,this_item[ll],this_item[item]),\n",
    "                                    'ed_ur':distance.euclidean(0,this_item[ur],this_item[item]),\n",
    "                                    'ed_lr':distance.euclidean(0,this_item[lr],this_item[item]),\n",
    "                                    'vd_ul':this_item[ul][0]-this_item[item][0],\n",
    "                                    'vd_ll':this_item[ll][0]-this_item[item][0],\n",
    "                                    'vd_ur':this_item[ur][0]-this_item[item][0],\n",
    "                                    'vd_lr':this_item[lr][0]-this_item[item][0],\n",
    "                                    'hd_ul':this_item[ul][1]-this_item[item][1],\n",
    "                                    'hd_ll':this_item[ll][1]-this_item[item][1],\n",
    "                                    'hd_ur':this_item[ur][1]-this_item[item][1],\n",
    "                                    'hd_lr':this_item[lr][1]-this_item[item][1]\n",
    "                                       }, ignore_index=True)\n",
    "\n",
    "    #except:\n",
    "    #    pass\n",
    "    return(test_data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('/home/ubuntu/test_df_points.pkl','rb') as fp:\n",
    "    data_df=dill.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>ratio</th>\n",
       "      <th>sr</th>\n",
       "      <th>sc</th>\n",
       "      <th>machine</th>\n",
       "      <th>piidata</th>\n",
       "      <th>nopiidata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ubuntu/efs/acrin_by_machine/machine_phot...</td>\n",
       "      <td>0.906229</td>\n",
       "      <td>-59</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>[(3055, 693), (3323, 687), (1448, 711), (1448,...</td>\n",
       "      <td>[(3475, 769), (3372, 1434), (3517, 1429), (333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ubuntu/efs/acrin_by_machine/machine_phot...</td>\n",
       "      <td>0.878613</td>\n",
       "      <td>95</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>[(1884, 798), (1454, 872), (1746, 876), (2022,...</td>\n",
       "      <td>[(3073, 1244), (3161, 790), (3191, 874), (2936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ubuntu/efs/acrin_by_machine/machine_phot...</td>\n",
       "      <td>0.853372</td>\n",
       "      <td>-130</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>[(1712, 530), (2600, 524), (2560, 598), (2478,...</td>\n",
       "      <td>[(3323, 599), (3198, 596), (3177, 520), (864, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ubuntu/efs/acrin_by_machine/machine_phot...</td>\n",
       "      <td>0.885532</td>\n",
       "      <td>242</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>[(2823, 845), (2392, 845), (1914, 959), (1453,...</td>\n",
       "      <td>[(3105, 840), (2866, 942), (3338, 839), (3381,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ubuntu/efs/acrin_by_machine/machine_phot...</td>\n",
       "      <td>0.910913</td>\n",
       "      <td>-170</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>[(3266, 616), (3221, 682), (3390, 683), (1649,...</td>\n",
       "      <td>[(3067, 818), (3337, 1503), (3219, 766), (1776...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fileName     ratio    sr   sc  \\\n",
       "0  /home/ubuntu/efs/acrin_by_machine/machine_phot...  0.906229   -59  175   \n",
       "1  /home/ubuntu/efs/acrin_by_machine/machine_phot...  0.878613    95   -2   \n",
       "2  /home/ubuntu/efs/acrin_by_machine/machine_phot...  0.853372  -130   42   \n",
       "3  /home/ubuntu/efs/acrin_by_machine/machine_phot...  0.885532   242  120   \n",
       "4  /home/ubuntu/efs/acrin_by_machine/machine_phot...  0.910913  -170  259   \n",
       "\n",
       "  machine                                            piidata  \\\n",
       "0       1  [(3055, 693), (3323, 687), (1448, 711), (1448,...   \n",
       "1       2  [(1884, 798), (1454, 872), (1746, 876), (2022,...   \n",
       "2       3  [(1712, 530), (2600, 524), (2560, 598), (2478,...   \n",
       "3       4  [(2823, 845), (2392, 845), (1914, 959), (1453,...   \n",
       "4       5  [(3266, 616), (3221, 682), (3390, 683), (1649,...   \n",
       "\n",
       "                                           nopiidata  \n",
       "0  [(3475, 769), (3372, 1434), (3517, 1429), (333...  \n",
       "1  [(3073, 1244), (3161, 790), (3191, 874), (2936...  \n",
       "2  [(3323, 599), (3198, 596), (3177, 520), (864, ...  \n",
       "3  [(3105, 840), (2866, 942), (3338, 839), (3381,...  \n",
       "4  [(3067, 818), (3337, 1503), (3219, 766), (1776...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1203 16:52:53.568477 140394239682368 deprecation.py:323] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=25, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.load_weights('weights_image_final_v2')\n",
    "import dill\n",
    "with open('/home/ubuntu/train_mean_mach.pkl','rb') as fp:\n",
    "    mean=dill.load(fp)\n",
    "with open('/home/ubuntu/train_std_mach.pkl','rb') as fp:\n",
    "    std=dill.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fb2f6284959b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     78\u001b[0m                              'for each key in: ' + str(names))\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicts = model.predict(X)\n",
    "predicts = np.argmax(predicts, axis=1)\n",
    "\n",
    "accuracy_score(Y, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for spot-checking data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(i,Te):\n",
    "    img = cv.imread(data_df.loc[0].fileName)\n",
    "    ratio=rand_scale = data_df.loc[0].ratio\n",
    "    sr=data_df.loc[0].sr\n",
    "    sc=data_df.loc[0].sc\n",
    "\n",
    "    old_size = img.shape[:2] # old_size is in (height, width) format\n",
    "\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    # new_size should be in (width, height) format\n",
    "\n",
    "    im = cv.resize(img, (new_size[1], new_size[0]))\n",
    "\n",
    "    top = int((old_size[0] - new_size[0])/2)\n",
    "    bottom = int((old_size[0] - new_size[0])/2)\n",
    "    left = int((old_size[1] - new_size[1])/2)\n",
    "    right = int((old_size[1] - new_size[1])/2)\n",
    "\n",
    "    if top+bottom+new_size[0] < old_size[0]:\n",
    "        top += 1\n",
    "    if left+right+new_size[1] < old_size[1]:\n",
    "        left += 1\n",
    "\n",
    "    color = [0, 0, 0]\n",
    "    img= cv.copyMakeBorder(im, top, bottom, left, right, cv.BORDER_CONSTANT,\n",
    "        value=color)\n",
    "\n",
    "    rows,cols,_ = img.shape\n",
    "    M = np.float32([[1,0,sc],[0,1,sr]])\n",
    "    img = cv.warpAffine(img,M,(cols,rows))\n",
    "    \n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    probs = model.predict(Te)\n",
    "\n",
    "    for this_point in range(len(test_data_set)):\n",
    "        box = test_data_set.iloc[this_point].boxx\n",
    "        if probs[this_point][0] > .5:\n",
    "            cv.rectangle(img, (box[0],box[1]),(box[2],box[3]), (0,0,0), -10)\n",
    "\n",
    "    plt.figure(figsize=(30,20))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_data_points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8b3a2c5376fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-caae4e140564>\u001b[0m in \u001b[0;36mcreate_df\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mboxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthis_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mpii_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnopii_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     data_df = data_df.append({'fileName': this_frame.fileName,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_data_points' is not defined"
     ]
    }
   ],
   "source": [
    "image_num = 200\n",
    "data_df= create_df(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3902df84ceb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmachine_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmachine_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "for image_num in range(10):\n",
    "    \n",
    "    image_num = random.randint(0,len(df))\n",
    "    X = create_test_data(image_num)\n",
    "    machine_pred = machine_model.predict(X)\n",
    "    machine_pred = np.argmax(machine_pred, axis=1)\n",
    "    data_df= create_df(image_num)\n",
    "    test_data_set = create_data_set(data_df,machine_pred,image_num)\n",
    "\n",
    "    test_data = test_data_set.to_numpy()\n",
    "    Te = test_data[:,:-2]\n",
    "    y_t = test_data[:,-2]\n",
    "    Te = Te.astype(float)\n",
    "    y_t = y_t.astype(float)\n",
    "    Te = [(x - mean)/std for x in Te]\n",
    "    Te = np.array(Te)\n",
    "\n",
    "    print_image(image_num,Te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2ebebfa6c315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data_set' is not defined"
     ]
    }
   ],
   "source": [
    "test_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14482758620689656\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "new_y = []\n",
    "new_predicts = []\n",
    "predicts = model.predict(Te)\n",
    "for i in range(len(predicts)):\n",
    "    new_predicts.append(round(predicts[i][0]))\n",
    "    #new_y.append(y_t[i][0])\n",
    "print(accuracy_score(y_t, new_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.randint(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-86b5e46d4e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrand_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "img = cv.imread(data_df.loc[i].fileName)\n",
    "ratio=rand_scale = data_df.loc[i].ratio\n",
    "sr=data_df.loc[i].sr\n",
    "sc=data_df.loc[i].sc\n",
    "\n",
    "\n",
    "old_size = img.shape[:2] # old_size is in (height, width) format\n",
    "\n",
    "new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "# new_size should be in (width, height) format\n",
    "\n",
    "im = cv.resize(img, (new_size[1], new_size[0]))\n",
    "\n",
    "top = int((old_size[0] - new_size[0])/2)\n",
    "bottom = int((old_size[0] - new_size[0])/2)\n",
    "left = int((old_size[1] - new_size[1])/2)\n",
    "right = int((old_size[1] - new_size[1])/2)\n",
    "\n",
    "if top+bottom+new_size[0] < old_size[0]:\n",
    "    top += 1\n",
    "if left+right+new_size[1] < old_size[1]:\n",
    "    left += 1\n",
    "\n",
    "color = [0, 0, 0]\n",
    "img= cv.copyMakeBorder(im, top, bottom, left, right, cv.BORDER_CONSTANT,\n",
    "    value=color)\n",
    "\n",
    "rows,cols,_ = img.shape\n",
    "M = np.float32([[1,0,sc],[0,1,sr]])\n",
    "img = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "for box in data_df.loc[i].boxx:\n",
    "    cv.rectangle(img, (box[0],box[1]),(box[2],box[3]), (0,255,0), 10)\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
